---
title: "Task_1"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(lubridate)
library(GGally)
library(cluster)
library(VIM)
library(fpc)
library(leaps)
library(ISLR)
library(glmnet)
library(ggvis)
set.seed(666)
```


```{r code setup}
spotify.clustering <- read_csv("inst/edited_spotify.csv")

clean_data <- spotify.clustering %>%
  mutate(AlbumReleaseDate = parse_date_time(AlbumReleaseDate, orders = c("y", "ym","ymd"))) %>%
  #Old-school grepl method
  mutate(Artist = ifelse(grepl("Beyonc*", Artist), 'Beyonce', Artist)) %>%
  #Tidyverse str_detect method
  mutate(Artist = ifelse(Artist %>% 
                           str_detect("Janelle Mon*"), 'Janelle Monae', Artist)) %>%
  mutate(AlbumBestChartPosition = ifelse(AlbumBestChartPosition %>% 
                           str_detect("#N/A"), 0, AlbumBestChartPosition)) %>%
    mutate(AlbumBestChartPosition= as.numeric(AlbumBestChartPosition)) %>%
  na.omit() %>%
  mutate(id = row_number()) %>%
  mutate(id = as.character(id))
sapply(data, class)

aggr(clean_data) # checks for missing data

test_data <- subset(clean_data, ((AlbumName == "A Girl Called Dusty") | 
                                 (AlbumName == "Action!") |
                                 (AlbumName == "Selling England By The Pound") |
                                 (AlbumName == "Carpenters") | 
                                 (AlbumName == "Ride On") |
                                 (AlbumName == "Autoamerican") |
                                 (AlbumName == "Selected Ambient Works 85-92") |    
                                 (AlbumName == "Different Class") |
                                 (AlbumName == "O") |
                                 (AlbumName == "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") |
                                 (AlbumName == "AM") |
                                 (AlbumName == "An Awesome Wave")))

training_data <- subset(clean_data, ((AlbumName != "A Girl Called Dusty") & 
                                     (AlbumName != "Action!") &
                                     (AlbumName != "Selling England By The Pound") &
                                     (AlbumName != "Carpenters") & 
                                     (AlbumName != "Ride On") &
                                     (AlbumName != "Autoamerican") &
                                     (AlbumName != "Selected Ambient Works 85-92") &    
                                     (AlbumName != "Different Class") &
                                     (AlbumName != "O") &
                                     (AlbumName != "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") &
                                     (AlbumName != "AM") &
                                     (AlbumName != "An Awesome Wave")))

training_data_subsetted <- training_data[c("TrackDuration", "TrackDanceability",
                                 "TrackEnergy", "TrackKey", "TrackLoudness",
                                 "TrackSpeechiness", "TrackAcousticness",
                                 "TrackInstrumentalness", "TrackLiveness", "TrackValence",
                                 "TrackTempo")]
```


A new popularity variable needs to be defined to take into account all the other popularity variables
```{r newPop, warnings = FALSE}
#Future maybe not implement due to time but could functionalise this and then use k fold cross validation but would take a LONG time to run, (hours).
#Looking at implementing new variables for each popularity variable
#Can then take this and normalise to give a score out of 100.
#To start with the whole training dataset will be used
normy <- function(x){
  as.numeric(x)
  quantile(x, c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), na.rm = TRUE)
}
#Assumption: NA means it didn't reach the charts, lower the position the better
abcp_normy <- normy(training_data$AlbumBestChartPosition)
anf_normy <- normy(training_data$ArtistNumFollowers)
awoc_normy <- normy(training_data$AlbumWeeksOnChart)
awn1_normy <- normy(training_data$AlbumWeeksNumberOne)
ap_normy <- normy(training_data$AlbumPopularity)
artp_normy <- normy(training_data$ArtistPopularity)

#Gets the 20% percentile for example
as.numeric(abcp_normy[6])

training_data <- training_data %>%
  mutate(album_bcp = if_else(AlbumBestChartPosition == 0, 1,
                         if_else(AlbumBestChartPosition == 1, 10,
                         if_else(AlbumBestChartPosition == 2, 9,
                         if_else(AlbumBestChartPosition == 3, 8,
                           0 ))))) %>% #... repeat for other variables
  mutate(artist_follow_n = 0) %>%
  mutate(album_pop_n = 0) %>%
  mutate(artist_pop_n = 0) %>%
  mutate(album_weeks_on_chart_n = if_else(AlbumWeeksOnChart == 0, 1, 0)) %>%
  mutate(album_weeks_number_1n = if_else(AlbumWeeksNumberOne == 0, 1, 0)) %>%
  mutate(popularity = -1) %>%
  mutate(AlbumReleaseDate = as.numeric(format(AlbumReleaseDate, "%y"))) %>%
  mutate(years_since_release = if_else(between(AlbumReleaseDate, 60, 99), (19 + (100 - AlbumReleaseDate)),
                                         (19 - AlbumReleaseDate)))
                                         

#album weeks number 1, this is fine as we are going > 0 and =< 1
for(i in 8:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksNumberOne[j] > as.numeric(awn1_normy[i]) &&
         training_data$AlbumWeeksNumberOne[j] <= as.numeric(awn1_normy[i + 1])){
    training_data$album_weeks_number_1n[j] = i
  }
  }
}

for(i in 2:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksOnChart[j] > as.numeric(awoc_normy[i]) &&
         training_data$AlbumWeeksOnChart[j] <= as.numeric(awoc_normy[i + 1])){
    training_data$album_weeks_on_chart_n[j] = i
  }
  }
}

#album weeks on chart

#albumchartposition
for(i in 6:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumBestChartPosition[j] > as.numeric(abcp_normy[i]) &&
         training_data$AlbumBestChartPosition[j] <= as.numeric(abcp_normy[i + 1])){
    training_data$album_bcp[j] = (12-i)
  }
  }
}

#Mutate at end to sort out end case
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistNumFollowers[j] >= as.numeric(anf_normy[i]) &&
         training_data$ArtistNumFollowers[j] < as.numeric(anf_normy[i + 1])){
    training_data$artist_follow_n[j] = i
  }
  }
}
#Create and update artist_popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistPopularity[j] >= as.numeric(artp_normy[i]) &&
         training_data$ArtistPopularity[j] < as.numeric(artp_normy[i + 1])){
    training_data$artist_pop_n[j] = i
  }
  }
}
#Create and update album popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumPopularity[j] >= as.numeric(ap_normy[i]) &&
         training_data$AlbumPopularity[j] < as.numeric(ap_normy[i + 1])){
    training_data$album_pop_n[j] = i
  }
  }
}
```
Defining a function to summarise the data input and define the y variable 
```{r}
spotify_summarise <- function(x){
  x %>%
     group_by(Artist, AlbumName, AlbumReleaseDate) %>%
  summarise(track_duration_mean = mean(TrackDuration),
            track_duration_IQR = IQR(TrackDuration),
            track_danceability_mean = mean(TrackDanceability),
            track_danceability_IQR = IQR(TrackDanceability),
            track_energy_mean = mean(TrackEnergy),
            track_energy_mean = mean(TrackEnergy),
            track_loudness_mean = mean(TrackLoudness),
            track_loudness_IQR = IQR(TrackLoudness),
            track_speechiness_mean = mean(TrackSpeechiness),
            track_speechiness_IQR = IQR(TrackSpeechiness),
            track_acousticness_mean = mean(TrackAcousticness),
            track_acousticness_IQR = IQR(TrackAcousticness),
            track_instrumentalness_mean = mean(TrackInstrumentalness),
            track_instrumentalness_IQR = IQR(TrackInstrumentalness),
            track_valence_mean = mean(TrackValence),
            track_valence_IQR = IQR(TrackValence),
            track_tempo_mean = mean(TrackTempo),
            track_tempo_IQR = IQR(TrackTempo),
            popularity = mean(popularity)
            
  )
}

define_y <- function(y){
y %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric() %>%
  na.omit()
}
```
First Popularity Combination
```{r}
#Could maybe add a years from release as a penalty to make newer songs higher rated or subset the data?
#Should probably add some sort of verification to the numbers for now they are arbitrary?
#Tried 2 and 5 for the multiplcation parameter in the years since release scaling 
#But these both resulted in higher MSE
training_data_pop_1 <- training_data %>%
  mutate(popularity = ((25 * training_data$album_pop_n + 25 * training_data$artist_pop_n +
                         25 * training_data$artist_follow_n + 10 * training_data$album_bcp +
                         10 * training_data$album_weeks_on_chart_n +
                         5 * training_data$album_weeks_number_1n)/(
                         10 * ((100 + 3 * training_data$years_since_release)/
                         (100 + training_data$years_since_release))))) %>%
  #Correcting for the max term which is not included in the if statement
  mutate(artist_follow_n = if_else(artist_follow_n == 0, 10, artist_follow_n)) %>%
  mutate(artist_pop_n = if_else(artist_pop_n == 0, 10, artist_pop_n)) %>%
  mutate(album_pop_n = if_else(album_pop_n == 0, 10, album_pop_n))


data_1 <- training_data_pop_1 %>%
  spotify_summarise %>% 
  ungroup() %>%
  select(-AlbumName, -Artist, -AlbumReleaseDate)
```

Second Popularity Combination
```{r}
#Could maybe add a years from release as a penalty to make newer songs higher rated or subset the data?
#Should probably add some sort of verification to the numbers for now they are arbitrary?
value <- 100/3
training_data_pop_2 <- training_data %>%
  mutate(popularity = ((value * training_data$album_pop_n + value * training_data$artist_pop_n +
                         value * training_data$artist_follow_n)/(
                         10 * ((100 + 3 * training_data$years_since_release)/
                         (100 + training_data$years_since_release))))) %>%
  #Correcting for the max term which is not included in the if statement
  mutate(artist_follow_n = if_else(artist_follow_n == 0, 10, artist_follow_n)) %>%
  mutate(artist_pop_n = if_else(artist_pop_n == 0, 10, artist_pop_n)) %>%
  mutate(album_pop_n = if_else(album_pop_n == 0, 10, album_pop_n))


data_2 <- training_data_pop_2 %>%
  spotify_summarise %>% 
  ungroup() %>%
  select(-AlbumName, -Artist, -AlbumReleaseDate)
```
Third Popularity Combination
```{r}
#Could maybe add a years from release as a penalty to make newer songs higher rated or subset the data?
#Should probably add some sort of verification to the numbers for now they are arbitrary?
value <- 100/6
training_data_pop_3 <- training_data %>%
  mutate(popularity = ((value * training_data$album_pop_n + value * training_data$artist_pop_n +
                         value * training_data$artist_follow_n + value * training_data$album_bcp +
                         value * training_data$album_weeks_on_chart_n +
                         value * training_data$album_weeks_number_1n)/(
                         10 * ((100 + 3 * training_data$years_since_release)/
                         (100 + training_data$years_since_release))))) %>%
  #Correcting for the max term which is not included in the if statement
  mutate(artist_follow_n = if_else(artist_follow_n == 0, 10, artist_follow_n)) %>%
  mutate(artist_pop_n = if_else(artist_pop_n == 0, 10, artist_pop_n)) %>%
  mutate(album_pop_n = if_else(album_pop_n == 0, 10, album_pop_n))


data_3 <- training_data_pop_3 %>%
  spotify_summarise %>% 
  ungroup() %>%
  select(-AlbumName, -Artist, -AlbumReleaseDate)
```

Looking at the the three datasets using best subset regression:
Dataset 1:
```{r}
#all subsets regression


m <- regsubsets(popularity ~ ., data = data_1)

summary(m)

#measures
par(mfrow = c(1,1))

plot(m, scale = "Cp")

plot(m, scale = "bic")

plot(m, scale = "adjr2")


#check Adjusted R2
rsq <- as.data.frame(summary(m)$adjr2)
names(rsq) <- "Adjusted-R2"
rsq %>% 
        ggvis(x=~ c(1:nrow(rsq)), y=~`Adjusted-R2` ) %>%
        layer_points(fill = ~`Adjusted-R2`) %>%
        add_axis("y", title = "Adjusted-R2`") %>% 
        add_axis("x", title = "Number of variables")

#the final Adjusted R2 is very high

reg.summary <- summary(m)


#compare RSS, Cp, bic, adjr2
par(mfrow=c(2,2))
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",type="l")
plot(reg.summary$adjr2 ,xlab="Number of Variables ", ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
points(which.max(reg.summary$adjr2),reg.summary$adjr2[which.max(reg.summary$adjr2)], col="red",cex=2,pch=20)
plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type='l')
which.min(reg.summary$cp )
points(which.min(reg.summary$cp ),reg.summary$cp [which.min(reg.summary$cp )],col="red",cex=2,pch=20)
plot(reg.summary$bic ,xlab="Number of Variables ",ylab="BIC",type='l')
which.min(reg.summary$bic )
points(which.min(reg.summary$bic ),reg.summary$bic [which.min(reg.summary$bic )],col="red",cex=2,pch=20)
par(mfrow=c(1,1))


coef(m, 8)


#a selected best model by adjr2
m1 <- lm( popularity ~  track_loudness_mean  + track_speechiness_mean+ track_speechiness_IQR+ track_acousticness_mean + track_acousticness_IQR + track_valence_mean +      track_valence_IQR  + track_tempo_mean  ,data= data_1)
summary(m1)

#predictions on testing data
preds <- predict(m1, newdata = data_1 )
mse_bs1 <- mean((preds - data_1$popularity)^2)
absolute_bs1 <- sqrt( mean((preds - data_1$popularity)^2) )
```
Dataset 2:
```{r}
#all subsets regression


m <- regsubsets(popularity ~ ., data = data_2)

summary(m)

#measures
par(mfrow = c(1,1))

plot(m, scale = "Cp")

plot(m, scale = "bic")

plot(m, scale = "adjr2")


#check Adjusted R2
rsq <- as.data.frame(summary(m)$adjr2)
names(rsq) <- "Adjusted-R2"
rsq %>% 
        ggvis(x=~ c(1:nrow(rsq)), y=~`Adjusted-R2` ) %>%
        layer_points(fill = ~`Adjusted-R2`) %>%
        add_axis("y", title = "Adjusted-R2`") %>% 
        add_axis("x", title = "Number of variables")

#the final Adjusted R2 is very high

reg.summary <- summary(m)


#compare RSS, Cp, bic, adjr2
par(mfrow=c(2,2))
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",type="l")
plot(reg.summary$adjr2 ,xlab="Number of Variables ", ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
points(which.max(reg.summary$adjr2),reg.summary$adjr2[which.max(reg.summary$adjr2)], col="red",cex=2,pch=20)
plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type='l')
which.min(reg.summary$cp )
points(which.min(reg.summary$cp ),reg.summary$cp [which.min(reg.summary$cp )],col="red",cex=2,pch=20)
plot(reg.summary$bic ,xlab="Number of Variables ",ylab="BIC",type='l')
which.min(reg.summary$bic )
points(which.min(reg.summary$bic ),reg.summary$bic [which.min(reg.summary$bic )],col="red",cex=2,pch=20)
par(mfrow=c(1,1))


coef(m, 8)


#a selected best model by adjr2
m1 <- lm( popularity ~  track_duration_IQR + track_danceability_mean + track_loudness_mean + track_speechiness_mean +  track_speechiness_IQR+ track_acousticness_IQR  +    track_valence_mean  +      track_tempo_mean ,data= data_2)
summary(m1)

#predictions on testing data
preds <- predict(m1, newdata = data_2)

absolute_bs2 <- sqrt( mean((preds - data_2$popularity)^2) )
mse_bs2 <- mean((preds - data_2$popularity)^2) 
```
Third Dataset:
```{r}
m <- regsubsets(popularity ~ ., data = data_3)

summary(m)

#measures
par(mfrow = c(1,1))

plot(m, scale = "Cp")

plot(m, scale = "bic")

plot(m, scale = "adjr2")


#check Adjusted R2
rsq <- as.data.frame(summary(m)$adjr2)
names(rsq) <- "Adjusted-R2"
rsq %>% 
        ggvis(x=~ c(1:nrow(rsq)), y=~`Adjusted-R2` ) %>%
        layer_points(fill = ~`Adjusted-R2`) %>%
        add_axis("y", title = "Adjusted-R2`") %>% 
        add_axis("x", title = "Number of variables")

#the final Adjusted R2 is very high

reg.summary <- summary(m)


#compare RSS, Cp, bic, adjr2
par(mfrow=c(2,2))
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",type="l")
plot(reg.summary$adjr2 ,xlab="Number of Variables ", ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
points(which.max(reg.summary$adjr2),reg.summary$adjr2[which.max(reg.summary$adjr2)], col="red",cex=2,pch=20)
plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type='l')
which.min(reg.summary$cp )
points(which.min(reg.summary$cp ),reg.summary$cp [which.min(reg.summary$cp )],col="red",cex=2,pch=20)
plot(reg.summary$bic ,xlab="Number of Variables ",ylab="BIC",type='l')
which.min(reg.summary$bic )
points(which.min(reg.summary$bic ),reg.summary$bic [which.min(reg.summary$bic )],col="red",cex=2,pch=20)
par(mfrow=c(1,1))


coef(m, 8)


#a selected best model by adjr2
m3 <- lm( popularity ~ track_duration_mean +   track_loudness_mean + track_speechiness_mean + track_speechiness_IQR + track_acousticness_IQR    +   track_valence_IQR  +      track_tempo_mean   +track_tempo_IQR,data= data_2)
summary(m3)

#predictions on testing data
preds <- predict(m3, newdata = data_3 )

absolute_bs3 <- sqrt(mean((preds - data_3$popularity)^2))
mse_bs3 <- mean((preds - data_3$popularity)^2)
```

Looking at ridge regression... The commented lines were used to visualise the datasets in our dummy runs but were not rerun as part of the actual methods
```{r ridgeregression}

#Get training_data_pop from EDA file
#Code based from http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html
ridge_reg <- function(data){
model_data <- data
output <- data.frame(matrix(0, nrow = 0, ncol = 2))
#Looking at the models with the whole dataset
x <- model.matrix(popularity ~ ., model_data )
y <- define_y(model_data)

grid <- 10^seq(10, -2, length = 100)
ridge_mod <- glmnet(x, y, alpha = 0)

#Looking at the model
#dim(coef(ridge_mod))
#plot(ridge_mod)    # Draw plot of coefficients

output <- data.frame(matrix(0, nrow = 0, ncol = 2))
for(i in 1:nrow(model_data)){
  train = model_data[-i,]

test <- model_data %>%
  setdiff(train)

x_train <- model.matrix(popularity ~ ., train)
x_test <- model.matrix(popularity ~ ., test)

y_train <- define_y(train)


y_test <- define_y(test)

cv.out <- cv.glmnet(x_train, y_train, alpha = 0) # Fit ridge regression model on training data
bestlam <- cv.out$lambda.min  # Select lamda that minimizes training MSE
ridge_mod <- glmnet(x_train, y_train, alpha= 0, lambda = bestlam, thresh = 1e-12)
ridge_pred <- predict(ridge_mod, s = bestlam, newx = x_test) # Use best lambda to predict test data
m <- mean((ridge_pred - y_test)^2) # Calculate test MSE
output[i,1] <- bestlam
output[i,2] <- m
}
output <- output %>%
  rename(best_lambda = X1, MSE = X2)
#plot(cv.out)
mean_lambda <- output %>%
  #Using median rather than mean as since we are only using 1 datapoint
  #for our test dataset, if it is anonamous it could lead to a slight bias
  summarise(lambda = median(output$best_lambda)) %>%
  as_vector()
#Fitting the model on the whole dataset as defined by the average 
#best lamda as calculated above using k-1 validation
#This is then returned as the output of the function
glmnet(x, y, alpha = 0, lambda = mean_lambda) 
}
```
Running Ridge Regression on our three datasets and looking at MSE.
```{r}
#Dataset 1
ridge_data1 <- ridge_reg(data_1)
#MSE of entire training dataset
x_data1 <- model.matrix(popularity ~ ., data_1)
y_data1 <- define_y(data_1)
ridge_pred_1 <- predict(ridge_data1, newx = x_data1)
mse_model1 <- mean((ridge_pred_1 - y_data1)^2)
absolute_ridge1 <- median(sqrt((ridge_pred_1 - y_data1)^2))
#Extract the coefficients of each variable in the model
ridge_data1$beta

#Dataset2
ridge_data2 <- ridge_reg(data_2)
#MSE of entire training dataset
x_data2 <- model.matrix(popularity ~ ., data_2)
y_data2 <- define_y(data_2)
ridge_pred_2 <- predict(ridge_data2, newx = x_data2)
mse_model2 <- mean((ridge_pred_2 - y_data2)^2)
absolute_ridge2 <- median(sqrt((ridge_pred_2 - y_data2)^2))
#Extract the coefficients of each variable in the model
ridge_data2$beta

#Dataset 3
ridge_data3 <- ridge_reg(data_3)
#MSE of entire training dataset
x_data3 <- model.matrix(popularity ~ ., data_3)
y_data3 <- define_y(data_3)
ridge_pred_3 <- predict(ridge_data3, newx = x_data3)
mse_model_3 <- mean((ridge_pred_3 - y_data3)^2)
absolute_ridge3 <- median(sqrt((ridge_pred_3 - y_data3)^2))
#Extract the coefficients of each variable in the model
ridge_data1$beta
```
Looking at the Lasso linear modelling method to see if we can improve on ridge regression
```{r ridgeregression}
set.seed(666)
#Get training_data_pop from EDA file
#Code based from http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html
lasso_reg <- function(data){
model_data <- data
output <- data.frame(matrix(0, nrow = 0, ncol = 2))
#Looking at the models with the whole dataset
x <- model.matrix(popularity ~ ., model_data )
y <- define_y(model_data)

grid <- 10^seq(10, -2, length = 100)
ridge_mod <- glmnet(x, y, alpha = 1)

output <- data.frame(matrix(0, nrow = 0, ncol = 2))
for(i in 1:nrow(model_data)){
  train = model_data[-i,]

test <- model_data %>%
  setdiff(train)

x_train <- model.matrix(popularity ~ ., train)
x_test <- model.matrix(popularity ~ ., test)

y_train <- define_y(train)


y_test <- define_y(test)

cv.out <- cv.glmnet(x_train, y_train, alpha = 1) # Fit lasso regression model on training data
bestlam <- cv.out$lambda.min  # Select lamda that minimizes training MSE
ridge_mod <- glmnet(x_train, y_train, alpha= 1, lambda = bestlam, thresh = 1e-12)
ridge_pred <- predict(ridge_mod, s = bestlam, newx = x_test) # Use best lambda to predict test data
m <- mean((ridge_pred - y_test)^2) # Calculate test MSE
output[i,1] <- bestlam
output[i,2] <- m
}
output <- output %>%
  rename(best_lambda = X1, MSE = X2)
#plot(cv.out)
mean_lambda <- output %>%
  #Using median rather than mean as since we are only using 1 datapoint
  #for our test dataset, if it is anonamous it could lead to a slight bias
  summarise(lambda = median(output$best_lambda)) %>%
  as_vector()
#Fitting the model on the whole dataset as defined by the average 
#best lamda as calculated above using k-1 validation
#This is then returned as the output of the function
glmnet(x, y, alpha = 1, lambda = mean_lambda) 
}
```
Lasso outputs
```{r}
lasso_data1 <- lasso_reg(data_1)
lx_data1 <- model.matrix(popularity ~ ., data_1)
ly_data1 <- define_y(data_1)
lasso_pred_1 <- predict(lasso_data1, newx = lx_data1)
lmse_model1 <- mean((lasso_pred_1 - ly_data1)^2)
absolute_lasso1 <- median(sqrt((lasso_pred_1 - ly_data1)^2))
#Extract the coefficients of each variable in the model
lasso_data1$beta

lasso_data2 <- lasso_reg(data_2)
lx_data2 <- model.matrix(popularity ~ ., data_2)
ly_data2 <- define_y(data_2)
lasso_pred_2 <- predict(lasso_data1, newx = lx_data2)
lmse_model2 <- mean((lasso_pred_2 - ly_data2)^2)
absolute_lasso2 <- median(sqrt((lasso_pred_2 - ly_data2)^2))
#Extract the coefficients of each variable in the model
lasso_data2$beta

lasso_data3 <- lasso_reg(data_3)
lx_data3 <- model.matrix(popularity ~ ., data_3)
ly_data3 <- define_y(data_3)
lasso_pred_3 <- predict(lasso_data3, newx = lx_data3)
lmse_model3 <- mean((lasso_pred_3 - ly_data3)^2)
absolute_lasso3 <- median(sqrt((lasso_pred_3 - ly_data3)^2))
#Extract the coefficients of each variable in the model
lasso_data3$beta
```
From this it seems the ridge regression model performs better in terms of MSE although the Lasso Model has the benefit of discarding some paremeters as the values associated with them are zero, whereas ridge gives a value to every input (no subset selection).
Summary of all the models:
```{r}
tibble(method = c("Best Subset Selection 1", "Best Subset Selection 2", "Best Subset Selection 3",
                  "Ridge 1","Ridge 2","Ridge 3", "Lasso 1", "Lasso 2", "Lasso 3"),
  MSE = c(mse_bs1, mse_bs2, mse_bs3, mse_model1, mse_model2, mse_model_3, lmse_model1, lmse_model2, lmse_model3), 
       AE = c(absolute_bs1, absolute_bs2, absolute_bs3, absolute_ridge1, absolute_ridge2, 
              absolute_ridge3, absolute_lasso1, absolute_lasso2, absolute_lasso3))

```
Reading the data in
```{r}
#saving the rdata
save.image(file = "ridge_lasso.Rdata")
#Can be loaded with:
#load("ridge_lasso.Rdata)
```