---
title: "Task_1"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(lubridate)
library(GGally)
library(cluster)
library(VIM)
library(fpc)
library(leaps)
library(ISLR)
library(glmnet)
```


```{r code setup}
spotify.clustering <- read_csv("inst/edited_spotify.csv")

clean_data <- spotify.clustering %>%
  mutate(AlbumReleaseDate = parse_date_time(AlbumReleaseDate, orders = c("y", "ym","ymd"))) %>%
  #Old-school grepl method
  mutate(Artist = ifelse(grepl("Beyonc*", Artist), 'Beyonce', Artist)) %>%
  #Tidyverse str_detect method
  mutate(Artist = ifelse(Artist %>% 
                           str_detect("Janelle Mon*"), 'Janelle Monae', Artist)) %>%
  mutate(AlbumBestChartPosition = ifelse(AlbumBestChartPosition %>% 
                           str_detect("#N/A"), 0, AlbumBestChartPosition)) %>%
  na.omit() %>%
  mutate(id = row_number()) %>%
  mutate(id = as.character(id))
sapply(data, class)

aggr(clean_data) # checks for missing data

test_data <- subset(clean_data, ((AlbumName == "A Girl Called Dusty") | 
                                 (AlbumName == "Action!") |
                                 (AlbumName == "Selling England By The Pound") |
                                 (AlbumName == "Carpenters") | 
                                 (AlbumName == "Ride On") |
                                 (AlbumName == "Autoamerican") |
                                 (AlbumName == "Selected Ambient Works 85-92") |    
                                 (AlbumName == "Different Class") |
                                 (AlbumName == "O") |
                                 (AlbumName == "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") |
                                 (AlbumName == "AM") |
                                 (AlbumName == "An Awesome Wave")))

training_data <- subset(clean_data, ((AlbumName != "A Girl Called Dusty") & 
                                     (AlbumName != "Action!") &
                                     (AlbumName != "Selling England By The Pound") &
                                     (AlbumName != "Carpenters") & 
                                     (AlbumName != "Ride On") &
                                     (AlbumName != "Autoamerican") &
                                     (AlbumName != "Selected Ambient Works 85-92") &    
                                     (AlbumName != "Different Class") &
                                     (AlbumName != "O") &
                                     (AlbumName != "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") &
                                     (AlbumName != "AM") &
                                     (AlbumName != "An Awesome Wave")))

training_data_subsetted <- training_data[c("TrackDuration", "TrackDanceability",
                                 "TrackEnergy", "TrackKey", "TrackLoudness",
                                 "TrackSpeechiness", "TrackAcousticness",
                                 "TrackInstrumentalness", "TrackLiveness", "TrackValence",
                                 "TrackTempo")]
```


A new popularity variable needs to be defined to take into account all the other popularity variables
```{r newPop, warnings = FALSE}
#Future maybe not implement due to time but could functionalise this and then use k fold cross validation but would take a LONG time to run, (hours).
#Looking at implementing new variables for each popularity variable
#Can then take this and normalise to give a score out of 100.
#To start with the whole training dataset will be used
normy <- function(x){
  as.numeric(x)
  quantile(x, c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), na.rm = TRUE)
}
#Assumption: NA means it didn't reach the charts, lower the position the better
abcp_normy <- normy(training_data$AlbumBestChartPosition)
anf_normy <- normy(training_data$ArtistNumFollowers)
awoc_normy <- normy(training_data$AlbumWeeksOnChart)
awn1_normy <- normy(training_data$AlbumWeeksNumberOne)
ap_normy <- normy(training_data$AlbumPopularity)
artp_normy <- normy(training_data$ArtistPopularity)

#Gets the 20% percentile for example
as.numeric(abcp_normy[6])

training_data <- training_data %>%
  mutate(album_bcp = if_else(AlbumBestChartPosition == 0, 1,
                         if_else(AlbumBestChartPosition == 1, 10,
                         if_else(AlbumBestChartPosition == 2, 9,
                         if_else(AlbumBestChartPosition == 3, 8,
                           0 ))))) %>% #... repeat for other variables
  mutate(artist_follow_n = 0) %>%
  mutate(album_pop_n = 0) %>%
  mutate(artist_pop_n = 0) %>%
  mutate(album_weeks_on_chart_n = if_else(AlbumWeeksOnChart == 0, 1, 0)) %>%
  mutate(album_weeks_number_1n = if_else(AlbumWeeksNumberOne == 0, 1, 0)) %>%
  mutate(popularity = -1) %>%
  mutate(AlbumReleaseDate = as.numeric(format(AlbumReleaseDate, "%y"))) %>%
  mutate(years_since_release = if_else(between(AlbumReleaseDate, 40, 99), (19 + (100 - AlbumReleaseDate)),
                                         (19 - AlbumReleaseDate)))
                                         


# training_data <- training_data %>%
#   mutate(album_bcp = 0) %>%
#   mutate(artist_follow_n = 0) %>%
#   mutate(album_pop_n = 0) %>%
#   mutate(artist_pop_n = 0) %>%
#   mutate(album_weeks_on_chart_n = 0) %>%
#   mutate(album_weeks_number_1n = 0)

#album weeks number 1, this is fine as we are going > 0 and =< 1
for(i in 8:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksNumberOne[j] > as.numeric(awn1_normy[i]) &&
         training_data$AlbumWeeksNumberOne[j] <= as.numeric(awn1_normy[i + 1])){
    training_data$album_weeks_number_1n[j] = i
  }
  }
}

for(i in 2:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksOnChart[j] > as.numeric(awoc_normy[i]) &&
         training_data$AlbumWeeksOnChart[j] <= as.numeric(awoc_normy[i + 1])){
    training_data$album_weeks_on_chart_n[j] = i
  }
  }
}

#album weeks on chart

#albumchartposition
for(i in 6:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumBestChartPosition[j] > as.numeric(abcp_normy[i]) &&
         training_data$AlbumBestChartPosition[j] <= as.numeric(abcp_normy[i + 1])){
    training_data$album_bcp[j] = (12-i)
  }
  }
}

#This is obviously wrong but not sure why... Looks like it should be working to me        
#Updating artist_followers, need to sort it for end case, last one needs to be <= not <0
# Can probably just mutate into it tbh at the end to fix all last cases.
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistNumFollowers[j] >= as.numeric(anf_normy[i]) &&
         training_data$ArtistNumFollowers[j] < as.numeric(anf_normy[i + 1])){
    training_data$artist_follow_n[j] = i
  }
  }
}
#Create and update artist_popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistPopularity[j] >= as.numeric(artp_normy[i]) &&
         training_data$ArtistPopularity[j] < as.numeric(artp_normy[i + 1])){
    training_data$artist_pop_n[j] = i
  }
  }
}
#Create and update album popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumPopularity[j] >= as.numeric(ap_normy[i]) &&
         training_data$AlbumPopularity[j] < as.numeric(ap_normy[i + 1])){
    training_data$album_pop_n[j] = i
  }
  }
}
#Could maybe add a years from release as a penalty to make newer songs higher rated or subset the data?
#Should probably add some sort of verification to the numbers for now they are arbitrary?
training_data_pop <- training_data %>%
  mutate(popularity = ((25 * training_data$album_pop_n + 25 * training_data$artist_pop_n +
                         25 * training_data$artist_follow_n + 10 * training_data$album_bcp +
                         10 * training_data$album_weeks_on_chart_n +
                         5 * training_data$album_weeks_number_1n)/10)) %>%
  #Correcting for the max term which is not included in the if statement
  mutate(artist_follow_n = if_else(artist_follow_n == 0, 10, artist_follow_n)) %>%
  mutate(artist_pop_n = if_else(artist_pop_n == 0, 10, artist_pop_n)) %>%
  mutate(album_pop_n = if_else(album_pop_n == 0, 10, album_pop_n))

bar_plot <- function(x){
  training_data_pop %>% 
  ggplot(aes_string(x = x)) + 
  geom_bar() +
    theme_bw() +
    scale_x_discrete(limits = c(0,2,4,6,8,10))
}
lapply(c("artist_follow_n", "artist_pop_n","album_pop_n","album_bcp",
         "album_weeks_on_chart_n", "album_weeks_number_1n"), bar_plot)
```



Looking at ridge regression...
```{r stephenmodels}
#Get training_data_pop from EDA file
#Code based from http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html
training_data_pop %>%
  group_by(Artist, AlbumName)


model_data <- training_data_pop[c("TrackDuration", "TrackDanceability",
                                 "TrackEnergy", "TrackKey", "TrackLoudness",
                                 "TrackSpeechiness", "TrackAcousticness",
                                 "TrackInstrumentalness", "TrackLiveness", "TrackValence",
                                 "TrackTempo", "popularity")] 
  

output <- data.frame(matrix(0, nrow = 0, ncol = 2))
#Looking at the models with the whole dataset
x <- model.matrix(popularity ~ ., model_data )
y <- model_data %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric()

grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(x, y, alpha = 0)

#Looking at the model
dim(coef(ridge_mod))
plot(ridge_mod)    # Draw plot of coefficients
########

#Now going to split the
#creating training and test data

##Takes about 3minutes to run:
output <- data.frame(matrix(0, nrow = 0, ncol = 2))
for(i in 1:100){
  train = model_data %>%
  sample_frac(0.8)

test = model_data %>%
  setdiff(train)

x_train = model.matrix(popularity ~ ., train)
x_test = model.matrix(popularity ~ ., test)

y_train = train %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric()

y_test = test %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric()


cv.out = cv.glmnet(x_train, y_train, alpha = 0) # Fit ridge regression model on training data
bestlam = cv.out$lambda.min  # Select lamda that minimizes training MSE
bestlam
ridge_mod = glmnet(x_train, y_train, alpha= 0, lambda = bestlam, thresh = 1e-12)
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test) # Use best lambda to predict test data
m <- mean((ridge_pred - y_test)^2) # Calculate test MSE
output[i,1] <- bestlam
output[i,2] <- m
}
output %>%
  rename(best_lambda = X1, MSE = X2)

#Takes about an hour to run approximately
#Results are more or less identical to those of the 3minute version
#So will tend to use that one for time purposes
output <- data.frame(matrix(0, nrow = 0, ncol = 2))
for(i in 1:nrow(model_data)){
  train = model_data[-i,]

test = model_data %>%
  setdiff(train)

x_train = model.matrix(popularity ~ ., train)
x_test = model.matrix(popularity ~ ., test)

y_train = train %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric()

y_test = test %>%
  select(popularity) %>%
  unlist() %>%
  as.numeric()


cv.out = cv.glmnet(x_train, y_train, alpha = 0) # Fit ridge regression model on training data
bestlam = cv.out$lambda.min  # Select lamda that minimizes training MSE
bestlam
ridge_mod = glmnet(x_train, y_train, alpha= 0, lambda = bestlam, thresh = 1e-12)
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test) # Use best lambda to predict test data
m <- mean((ridge_pred - y_test)^2) # Calculate test MSE
output[i,1] <- bestlam
output[i,2] <- m
}
output %>%
  rename(best_lambda = X1, MSE = X2)
#Saving the output as it takes an hour to run
#save.image(file = "ridge_hour_cross_validation.Rdata")
# can be loaded with
#load("ridge_hour_cross_validation.Rdata")
plot(cv.out)
# Next we fit a ridge regression model on the training set, and evaluate its MSE on the test set, using  best lambda. Note the use of the predict() function again: this time we get predictions for a test set, by replacing type="coefficients" with the newx argument
# Calculating average best_lambda
# Calculating average MSE


```