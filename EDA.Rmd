---
title: "EDA"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(lubridate)
library(GGally)
library(cluster)
library(VIM)
library(fpc)
library(leaps)

```

Firstly, we'll setup the import the dataset and split it into training and test data.
```{r code setup}
spotify.clustering <- read_csv("inst/edited_spotify.csv")

clean_data <- spotify.clustering %>%
  mutate(AlbumReleaseDate = parse_date_time(AlbumReleaseDate, orders = c("y", "ym","ymd"))) %>%
  #Old-school grepl method
  mutate(Artist = ifelse(grepl("Beyonc*", Artist), 'Beyonce', Artist)) %>%
  #Tidyverse str_detect method
  mutate(Artist = ifelse(Artist %>% 
                           str_detect("Janelle Mon*"), 'Janelle Monae', Artist)) %>%
  mutate(AlbumBestChartPosition = ifelse(AlbumBestChartPosition %>% 
                           str_detect("#N/A"), 0, AlbumBestChartPosition)) %>%
  mutate(AlbumBestChartPosition = as.numeric(AlbumBestChartPosition)) %>%
  na.omit() %>%
  mutate(id = row_number()) %>%
  mutate(id = as.character(id)) 
sapply(data, class)

aggr(clean_data) # checks for missing data

test_data <- subset(clean_data, ((AlbumName == "A Girl Called Dusty") | 
                                 (AlbumName == "Action!") |
                                 (AlbumName == "Selling England By The Pound") |
                                 (AlbumName == "Carpenters") | 
                                 (AlbumName == "Ride On") |
                                 (AlbumName == "Autoamerican") |
                                 (AlbumName == "Selected Ambient Works 85-92") |    
                                 (AlbumName == "Different Class") |
                                 (AlbumName == "O") |
                                 (AlbumName == "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") |
                                 (AlbumName == "AM") |
                                 (AlbumName == "An Awesome Wave")))

training_data <- subset(clean_data, ((AlbumName != "A Girl Called Dusty") & 
                                     (AlbumName != "Action!") &
                                     (AlbumName != "Selling England By The Pound") &
                                     (AlbumName != "Carpenters") & 
                                     (AlbumName != "Ride On") &
                                     (AlbumName != "Autoamerican") &
                                     (AlbumName != "Selected Ambient Works 85-92") &    
                                     (AlbumName != "Different Class") &
                                     (AlbumName != "O") &
                                     (AlbumName != "The Elder Scrolls IV: Oblivion: Original Game Soundtrack") &
                                     (AlbumName != "AM") &
                                     (AlbumName != "An Awesome Wave")))

training_data_subsetted <- training_data[c("TrackDuration", "TrackDanceability",
                                 "TrackEnergy", "TrackKey", "TrackLoudness",
                                 "TrackSpeechiness", "TrackAcousticness",
                                 "TrackInstrumentalness", "TrackLiveness", "TrackValence",
                                 "TrackTempo")]
```


## General EDA
```{r summarisies}
MyData = {training_data %>% 
    group_by(Artist,AlbumName,AlbumPopularity) %>% 
    summarize(AlbumDanceability = mean(TrackDanceability),
              AlbumLoudness = mean(TrackLoudness),
              AlbumSpeechiness = mean(TrackSpeechiness),
              AlbumDuration = mean(TrackDuration),
              AlbumNumber = mean(TrackNumber),	
              AlbumEnergy = mean(TrackEnergy),	
              AlbumKey = mean(TrackKey),	
              AlbumMode = mean(TrackMode),	
              AlbumAcousticness = mean(TrackAcousticness),	
              AlbumInstrumentalness = mean(TrackInstrumentalness),	
              AlbumLiveness = mean(TrackLiveness),
              AlbumValence = mean(TrackValence),
              AlbumTempo = mean(TrackTempo),	
              AlbumTimeSignature = mean(TrackTimeSignature) )}


#the mean method

MyData1 = {training_data %>% 
    group_by(ArtistPopularity) %>% 
    summarize(ArtistDanceability = mean(TrackDanceability),
              ArtistLoudness = mean(TrackLoudness),
              ArtistSpeechiness = mean(TrackSpeechiness),
              ArtistDuration = mean(TrackDuration),
              ArtistNumber = mean(TrackNumber),	
              ArtistEnergy = mean(TrackEnergy),	
              ArtistKey = mean(TrackKey),	
              ArtistMode = mean(TrackMode),	
              ArtistAcousticness = mean(TrackAcousticness),	
              ArtistInstrumentalness = mean(TrackInstrumentalness),	
              ArtistLiveness = mean(TrackLiveness),
              ArtistValence = mean(TrackValence),
              ArtistTempo = mean(TrackTempo),	
              ArtistTimeSignature = mean(TrackTimeSignature) )}


```

## Specific Task 1 EDA
```{r album popularity}
MyData2 = {training_data %>% 
    group_by(AlbumPopularity) %>% 
    summarize(AlbumDanceability = mean(TrackDanceability),
              AlbumLoudness = mean(TrackLoudness),
              AlbumSpeechiness = mean(TrackSpeechiness),
              AlbumDuration = mean(TrackDuration),
              AlbumNumber = mean(TrackNumber),	
              AlbumEnergy = mean(TrackEnergy),	
              AlbumKey = mean(TrackKey),	
              AlbumMode = mean(TrackMode),	
              AlbumAcousticness = mean(TrackAcousticness),	
              AlbumInstrumentalness = mean(TrackInstrumentalness),	
              AlbumLiveness = mean(TrackLiveness),
              AlbumValence = mean(TrackValence),
              AlbumTempo = mean(TrackTempo),	
              AlbumTimeSignature = mean(TrackTimeSignature) )}

#ggpairs(MyData2)

MyData2 %>% ggplot(aes(x =AlbumDanceability,y = AlbumPopularity)) + geom_point()  + geom_smooth()

MyData2 %>% ggplot(aes(x = AlbumLoudness,y = AlbumPopularity)) + geom_point()  + geom_smooth()

MyData2 %>% ggplot(aes(x =  AlbumEnergy ,y = AlbumPopularity)) + geom_point()  + geom_smooth()

MyData2 %>% ggplot(aes(x =  AlbumTimeSignature   ,y = AlbumPopularity)) + geom_point()  + geom_smooth()
```

A new popularity variable needs to be defined to take into account all the other popularity variables
```{r newPop, warnings = FALSE}
#Looking at implementing new variables for each popularity variable
#Can then take this and normalise to give a score out of 100.
#To start with the whole training dataset will be used
normy <- function(x){
  as.numeric(x)
  quantile(x, c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), na.rm = TRUE)
}
#Assumption: NA means it didn't reach the charts, lower the position the better
abcp_normy <- normy(training_data$AlbumBestChartPosition)
anf_normy <- normy(training_data$ArtistNumFollowers)
awoc_normy <- normy(training_data$AlbumWeeksOnChart)
awn1_normy <- normy(training_data$AlbumWeeksNumberOne)
ap_normy <- normy(training_data$AlbumPopularity)
artp_normy <- normy(training_data$ArtistPopularity)

#Gets the 20% percentile for example
as.numeric(abcp_normy[6])

training_data <- training_data %>%
  mutate(album_bcp = if_else(AlbumBestChartPosition == 0, 1,
                         if_else(AlbumBestChartPosition == 1, 10,
                         if_else(AlbumBestChartPosition == 2, 9,
                         if_else(AlbumBestChartPosition == 3, 8,
                           0 ))))) %>% #... repeat for other variables
  mutate(artist_follow_n = 0) %>%
  mutate(album_pop_n = 0) %>%
  mutate(artist_pop_n = 0) %>%
  mutate(album_weeks_on_chart_n = if_else(AlbumWeeksOnChart == 0, 1, 0)) %>%
  mutate(album_weeks_number_1n = if_else(AlbumWeeksNumberOne == 0, 1, 0)) %>%
  mutate(popularity = -1)

# training_data <- training_data %>%
#   mutate(album_bcp = 0) %>%
#   mutate(artist_follow_n = 0) %>%
#   mutate(album_pop_n = 0) %>%
#   mutate(artist_pop_n = 0) %>%
#   mutate(album_weeks_on_chart_n = 0) %>%
#   mutate(album_weeks_number_1n = 0)

#album weeks number 1, this is fine as we are going > 0 and =< 1
for(i in 8:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksNumberOne[j] > as.numeric(awn1_normy[i]) &&
         training_data$AlbumWeeksNumberOne[j] <= as.numeric(awn1_normy[i + 1])){
    training_data$album_weeks_number_1n[j] = i
  }
  }
}

for(i in 2:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumWeeksOnChart[j] > as.numeric(awoc_normy[i]) &&
         training_data$AlbumWeeksOnChart[j] <= as.numeric(awoc_normy[i + 1])){
    training_data$album_weeks_on_chart_n[j] = i
  }
  }
}

#album weeks on chart

#albumchartposition
for(i in 6:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumBestChartPosition[j] > as.numeric(abcp_normy[i]) &&
         training_data$AlbumBestChartPosition[j] <= as.numeric(abcp_normy[i + 1])){
    training_data$album_bcp[j] = (12-i)
  }
  }
}

#This is obviously wrong but not sure why... Looks like it should be working to me        
#Updating artist_followers, need to sort it for end case, last one needs to be <= not <0
# Can probably just mutate into it tbh at the end to fix all last cases.
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistNumFollowers[j] >= as.numeric(anf_normy[i]) &&
         training_data$ArtistNumFollowers[j] < as.numeric(anf_normy[i + 1])){
    training_data$artist_follow_n[j] = i
  }
  }
}
#Create and update artist_popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$ArtistPopularity[j] >= as.numeric(artp_normy[i]) &&
         training_data$ArtistPopularity[j] < as.numeric(artp_normy[i + 1])){
    training_data$artist_pop_n[j] = i
  }
  }
}
#Create and update album popularity
for(i in 1:10){
  for(j in 1:nrow(training_data)){
      if(training_data$AlbumPopularity[j] >= as.numeric(ap_normy[i]) &&
         training_data$AlbumPopularity[j] < as.numeric(ap_normy[i + 1])){
    training_data$album_pop_n[j] = i
  }
  }
}
#Could maybe add a years from release as a penalty to make newer songs higher rated or subset the data?
#Should probably add some sort of verification to the numbers for now they are arbitrary?
training_data_pop <- training_data %>%
  mutate(popularity = ((25 * training_data$album_pop_n + 25 * training_data$artist_pop_n +
                         25 * training_data$artist_follow_n + 10 * training_data$album_bcp +
                         10 * training_data$album_weeks_on_chart_n +
                         5 * training_data$album_weeks_number_1n)/10))


bar_plot <- function(x){
  training_data %>% 
  ggplot(aes_string(x = x)) + 
  geom_bar() +
    theme_bw() +
    scale_x_discrete(limits = c(0,2,4,6,8,10))
}
lapply(c("artist_follow_n", "artist_pop_n","album_pop_n","album_bcp",
         "album_weeks_on_chart_n", "album_weeks_number_1n"), bar_plot)
```
```{r leaps}
#all subsets regression
m <- regsubsets(ArtistPopularity ~ ., data = training_data)

summary(m)

par(mfrow = c(1,1))

plot(m, scale = "Cp")

plot(m, scale = "bic")

plot(m, scale = "adjr2")


#a selected best model by BIC
m1 <- lm(ArtistPopularity ~ ArtistDanceability + ArtistAcousticness + ArtistValence,data=training_data)
summary(m1)

#all subsets regression
m <- regsubsets( AlbumPopularity ~ ., data = MyData2)

summary(m)

par(mfrow = c(1,1))

plot(m, scale = "Cp")

plot(m, scale = "bic")

plot(m, scale = "adjr2")


#a selected best model by BIC
m1 <- lm(AlbumPopularity ~ AlbumDanceability + AlbumAcousticness + AlbumValence,data=MyData2)
summary(m1)
```
## Specific Task 2 EDA
Things I want to do:

  - figure out which factors are relevant and how to remove the useless ones;
  - try and figure out a number of clusters (maybe use pamk() in the  fpc package),
    or maybe by using the genre strings to create a set of theoretical clusters;
  - test out the nstart option in kmeans();
  - use pam() instead of kmeans();
  - try other clustering algorithms that don't require a number of clusters;
  - write a weighting function to use on songs.  
```{r clustering}
#Genre analysis using stringr to extract the most commonly appearing words
spotify.genres <- read_csv("inst/edited_spotify.csv") %>% 
  mutate(ArtistGenres = strsplit(ArtistGenres, ","))

genres <- na.omit(unique(unlist(spotify.genres$ArtistGenres)))

split_genres <- NULL

for(i in 1:length(genres)) {
  split_genres[i] <- strsplit(genres[i], " ")
}

genre_words <- unlist(split_genres)

unique_genre_words <- unique(genre_words)

genre_words_table <- subset(as.data.frame(table(genre_words)), (Freq > 7))

genre_freq_plot <- ggplot(data = genre_words_table, aes(x=genre_words, y=Freq)) + geom_col()

print(genre_freq_plot)

#Looking at the clusters with 6 as shown from the genre analysis
clusters <- pam(training_data, 6)
plotcluster(training_data, clusters$cluster, color = TRUE, shade = TRUE, labels = 2, lines = 0)
```

Code from clustering.rmd
```{r find genres}

genres <- mutate(training_data, ArtistGenres = strsplit(ArtistGenres, ","))$ArtistGenres %>% 
  unlist() %>% unique() %>% na.omit()

split_genres <- NULL

for(i in 1:length(genres)) {
  split_genres[i] <- strsplit(genres[i], " ")
}

genre_words <- unlist(split_genres)

genre_words <- replace(genre_words, (genre_words == "hip" | genre_words == "hop"), "hip-hop")

unique_genre_words <- unique(genre_words)

genre_freq_plot <- subset(as.data.frame(table(genre_words)), (Freq > 8)) %>% 
  ggplot(aes(x=genre_words, y=Freq)) + geom_col()

print(genre_freq_plot)

```

```{r link genres to tracks}

# associate tracks that have multiple genres with the most frequent genre (since these will be broader)

training_data_genre <- training_data %>% mutate(TrueCluster = (row_number()-row_number()))

for(i in 1:length(training_data_genre$ArtistID)) {
  if(str_detect(training_data$ArtistGenres[i], "folk")) {training_data$TrueCluster[i] <- 5}
  if(str_detect(training_data$ArtistGenres[i], "indie")) {training_data$TrueCluster[i] <- 4}
  if(str_detect(training_data$ArtistGenres[i], "hip")) {training_data$TrueCluster[i] <- 3}
  if(str_detect(training_data$ArtistGenres[i], "hop")) {training_data$TrueCluster[i] <- 3}
  if(str_detect(training_data$ArtistGenres[i], "pop")) {training_data$TrueCluster[i] <- 2}
  if(str_detect(training_data$ArtistGenres[i], "rock")) {training_data$TrueCluster[i] <- 1}
}

View(training_data_genre)
```

```{r clustering}

clustering_training_data <- training_data[c("TrackDuration", "TrackDanceability",
                                            "TrackEnergy", "TrackKey", "TrackLoudness",
                                            "TrackSpeechiness", "TrackAcousticness",
                                            "TrackInstrumentalness", "TrackLiveness", 
                                            "TrackValence", "TrackTempo")]

clusters <- pam(clustering_training_data, 6)

plotcluster(clustering_training_data, clusters$cluster)

```


EDA code from task_2
Variable distributions
```{r clustering, message = FALSE}

# Not sure why gather doesn't work, looks like it should as all attributes are numeric but anyway
# distributions <- clean_data %>%
#   gather(key = key, value = value) %>%
#   subset(key %in% colnames(clean_data[15:27])) %>%
#   ggplot() +
#   geom_density(aes(value)) +
#   facet_wrap(~key, scales = "free") +
#   theme_classic()


#print(distributions) commented out because it takes forever to run

ggpairs_1 <- ggpairs(data = training_data_subsetted, columns = 15:27, title = "GGpairs")

#print(ggpairs_1) see above

#Puts each song in  a cluster based on ALL numeric discriptors
cluster_1 <- training_data_subsetted %>%
  select(colnames(training_data_subsetted[15:27]), -TrackMode) %>%
  kmeans(50,100,1)
clusters <- cluster_1$cluster %>%
  enframe(name = "id") %>%
  mutate(id = as.character(id))

#Not sure why not merging think it should
clean_data <- right_join(training_data_subsetted, clusters, by = "id")  %>%
  rename_(cluster = "value")
tibbled <- tibble(clean_data, cluster_1$cluster)
```

